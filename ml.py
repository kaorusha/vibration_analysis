from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
import signal_processing
from skfeature.function.similarity_based import fisher_score
from sklearn import svm
from sklearn.metrics import accuracy_score, mean_squared_error

import shap
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
#from xgboost.sklearn import XGBRegressor
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn import tree

def shapley_value(x_train:np.ndarray, x_test:np.ndarray, y_train:np.ndarray, y_test:np.ndarray, X:pd.DataFrame):
    shap.initjs()
    xgb_model = XGBRegressor(n_estimators=1000, max_depth=10, learning_rate=0.001, random_state=0)
    xgb_model.fit(x_train, y_train)
    y_predict = xgb_model.predict(x_test)
    print(y_predict)
    mean_squared_error(y_test, y_predict)**(0.5)
    explainer = shap.TreeExplainer(xgb_model)
    shap_values = explainer.shap_values(x_train)
    shap.summary_plot(shap_values, features=x_train, feature_names=X.columns)
    acc = accuracy_score(y_test, y_predict)
    print(acc)

def fisher_score_show(x_train:np.ndarray, x_test:np.ndarray, y_train:np.ndarray, y_test:np.ndarray):
    score = fisher_score.fisher_score(x_train, y_train)
    idx = fisher_score.feature_ranking(score)
    num_fea = 5
    
    plt.figure(layout="constrained")
    plt.bar(range(len(score)), score)
    plt.xlabel('Feature Index')
    plt.ylabel('Fisher Score')
    plt.title('Fisher Score for Each Feature')
    for i in range(num_fea):
        plt.annotate(idx[i], 
                     xy=(idx[i], score[idx[i]]), rotation=0, xycoords='data',
                     xytext=(0,0), textcoords='offset pixels')
    plt.show()
    
    selected_feature_train = x_train[:, idx[0:num_fea]]
    selected_feature_test = x_test[:, idx[0:num_fea]]
    clf = svm.LinearSVC(dual=False)
    clf.fit(selected_feature_train, y_train)
    y_predict = clf.predict(selected_feature_test)
    acc = accuracy_score(y_test, y_predict)
    print(acc)

def compare_target_predict(df:pd.DataFrame, target:str, predict:str):
    '''
    show wrong prediction spectrum

    Parameters
    ----------
    df : input dataframe
    target : str
        name pf target column
    predict : str
        name of predict column
    
    Examples
    --------
    >>> compare_target_predict(df, 'Type', 'Predict')
    '''
    df_wrong = df.loc[df[target] != df[predict], :]
    fig, axs = plt.subplots(1,1, layout='constrained')
    for i in df_wrong.index:
        axs.plot(df_wrong.loc[i][:151], label= i + ': target %i predict %i'%(df_wrong.loc[i, 'Type'], df_wrong.loc[i, 'Predict']))
    axs.set_xticks(np.arange(0,151, step=10))
    axs.set_yscale('log')
    axs.legend()
    plt.show()

def predict(psd_file:str, joblib:str, keyword:str, col:int, column:list):
    '''
    load psd spectrum, and load model, output the predict result

    Parameters
    ----------
    psd_file : str
            psd spectrum generated by `acc_processing_excel()`. The samples are saved in separated sheets, 
            the column label in each sheets is the sensor channel, and the index is the order number.
            The psd result is averaged by windows.
    joblib : str
            file name of the trained classification model
    keyword : str
            selected sensor channel
    col : int
            controls the feature number to match the model feature number
    column : list
            controls the column label to match the model feature labels
    
    Examples
    --------
    >>> X = signal_processing.read_parquet_keyword(
            'lr_left',
            dir = '../../test_data//psd_100%//psd_window_high_resolution_100%//', 
            parse_func=signal_processing.parse_digital).sample(frac=1).reset_index(drop=True)
        predict(psd_file='../../test_data//20250410_test_samples//psd_100%//psd_high_resolution.xlsx', 
                joblib='../../model//100%_high_resolution//lr_left_high_resolution_set1_1280_v1.joblib',
                keyword='lr_left', col=1280, column=X.columns)
    '''
    from joblib import load
    df = signal_processing.read_sheets(psd_file, usecols=[0,1,2,3], combine=True)
    df = df.transpose()
    # add columns to describe the sensor channel and the sample_num
    df['channel'] = [name[7:] for name in df.index]
    df['sample_num'] = [name[:6] for name in df.index]
    
    # select a particular channel and shuffle
    X_test = df.loc[df['channel'] == keyword].reset_index(drop=True)
    X_test = X_test.reindex(columns=column)
    X_test = X_test.iloc[:, :col]
    # 匯入模型
    clf = load(joblib)
    # 模型預測測試
    res = df.loc[df['channel'] == keyword].iloc[:, -1:]
    res['predict'] = clf.predict(X_test)
    print(res)

if __name__ == '__main__':
    X = signal_processing.read_parquet_keyword('lr_left', 
                                           dir = '../../test_data//psd_100%//psd_window_high_resolution_100%//', 
                                           parse_func=signal_processing.parse_digital).sample(frac=1).reset_index(drop=True)
    predict(psd_file='../../test_data//20250410_test_samples//psd_100%//psd_high_resolution.xlsx', 
            joblib='../../model//100%_high_resolution//lr_left_high_resolution_set1_1280_v1.joblib',
            keyword='lr_left', col=1280, column=X.columns)