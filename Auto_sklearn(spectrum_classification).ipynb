{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">This node book is modified from https://github.com/andy6804tw/crazyai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_wiF0zJkSgAM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDIdhqeuSgAQ"
      },
      "source": [
        "## 1) 載入資料集\n",
        "### 1.1) loading PSD spectrum from excel or parquet files\n",
        "PSD spectrum is calculated from accelerometer data recordings.\n",
        "Each sample records 10 seconds for 2 times with 3 accelerometers attached on different position:\n",
        "* 1st run: left, right, and axial (channel labels are: lr_left, lr_right, and lr_axial).\n",
        "* 2ed run: up, down, and the axial is the same as 1st run((channel labels are: ud_up, ud_down, and ud_axial)).\n",
        "\n",
        "The sample are running with 20 and 100 duty, and also using normal(1 spike per order) and high resolution(10 spikes per order).\n",
        "Therefore there are 4 different types of PSD spectrum.\n",
        "\n",
        "|  duty | resolution | order number* | feature labels |\n",
        "|-------|------------|---------------|----------------|\n",
        "| 20    | normal     | 512  | 0, 1, 2, ... 512 |\n",
        "| 20    | high       | 5120 | 0.0, 0.1, 0.2, ... 512.0 |\n",
        "| 100   | normal     | 128  | 0, 1, 2, ... 128 |\n",
        "| 100   | high       | 1280 | 0.0, 0.1, 0.2, ... 128.0 |\n",
        "\n",
        "* order number: according to data points per round. The features may not all be used for training to improve the model performance.\n",
        "\n",
        "when loading data, the sample_num is added in the last column, this sample_num is used for labeling normal or abnormal target\n",
        "#### * option1: psd spectrum (averaged over windows)\n",
        ">> samples are not enough when we use averaged psd, that means only one psd for each sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "loIQUmCaSgAS",
        "outputId": "54333741-317a-4a29-f6e6-9199c6d41566"
      },
      "outputs": [],
      "source": [
        "import signal_processing\n",
        "df = signal_processing.read_sheets('../../test_data//psd_100%//psd_100%.xlsx', usecols=[0,1,2,3], combine=True).transpose()\n",
        "# add columns to describe the sensor channel and the sample_num\n",
        "df['channel'] = [name[7:] for name in df.index]\n",
        "df['sample_num'] = [name[:6] for name in df.index]\n",
        "X = df.loc[df['channel'] == 'lr_left'].sample(frac = 1).reset_index(drop=True)\n",
        "y = np.array([signal_processing.class_label(sample_num) for sample_num in X['sample_num']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### * option2: psd spectrum (unaveraged)\n",
        "Each rounds creates a spectrum sample to enlarge the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "read psd_window_000039_lr_left.parquet.gzip\n",
            "read psd_window_000027_lr_left.parquet.gzip\n",
            "read psd_window_000051_lr_left.parquet.gzip\n",
            "read psd_window_000050_lr_left.parquet.gzip\n",
            "read psd_window_000030_lr_left.parquet.gzip\n",
            "read psd_window_004073_lr_left.parquet.gzip\n",
            "read psd_window_004802_lr_left.parquet.gzip\n",
            "read psd_window_000037_lr_left.parquet.gzip\n",
            "read psd_window_000045_lr_left.parquet.gzip\n",
            "read psd_window_004124_lr_left.parquet.gzip\n",
            "read psd_window_003861_lr_left.parquet.gzip\n",
            "read psd_window_003720_lr_left.parquet.gzip\n",
            "read psd_window_000785_lr_left.parquet.gzip\n",
            "read psd_window_000048_lr_left.parquet.gzip\n",
            "read psd_window_000053_lr_left.parquet.gzip\n",
            "read psd_window_000052_lr_left.parquet.gzip\n",
            "read psd_window_000022_lr_left.parquet.gzip\n",
            "read psd_window_003735_lr_left.parquet.gzip\n",
            "read psd_window_004072_lr_left.parquet.gzip\n",
            "read psd_window_001833_lr_left.parquet.gzip\n",
            "read psd_window_002577_lr_left.parquet.gzip\n",
            "Index([         0.0,          1.0,          2.0,          3.0,          4.0,\n",
            "                5.0,          6.0,          7.0,          8.0,          9.0,\n",
            "       ...\n",
            "              504.0,        505.0,        506.0,        507.0,        508.0,\n",
            "              509.0,        510.0,        511.0,        512.0, 'sample_num'],\n",
            "      dtype='object', length=514)\n"
          ]
        }
      ],
      "source": [
        "keyword='lr_left'\n",
        "df = ml.load_data(format='parquet', dir='../../test_data//psd_100%//psd_window_100%//', keyword)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2) preprocessing\n",
        "#### 1.2.1. Add additional information to calculate the stats like mean and std of specified order range\n",
        "this is experimental for improving test accuracy\n",
        "#### 1.2.2. Drop high order features\n",
        "according to [include enough data](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular101#include-enough-data), for Classification problem: 50 rows x the number features\n",
        "#### 1.3.3. Transfer feature label type from numerical to string\n",
        "`autosklearn` takes `int` or `string` for feature label type, and the labels of model training data need to be identical with testing data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculate between 30 and 80\n"
          ]
        }
      ],
      "source": [
        "col = 80\n",
        "X = ml.preprocess_features(df, col=col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec1q-45XSgAT"
      },
      "source": [
        "## 2) 切割訓練集與測試集\n",
        "### 2.1) option 1: use all sample data for train/test (not recommended, causing data leakage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop unused column\n",
        "X = X.iloc[:, :513]\n",
        "X.reset_index(drop=True, inplace=True)\n",
        "print(X)\n",
        "print(y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print('train shape:', X_train.shape)\n",
        "print('test shape:', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2) option 2: use partial sample data for train and another partial sample for test\n",
        "\n",
        "#### 2.2.1) Simplify 3 categories from (0,1,2) to (0,1) for better result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2.2) Separate train/test samples to avoid data leakage\n",
        "* optional1: select a proportion of sample_num to be test sample, so the train and test sets are different in part number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_sample = df.value_counts(subset='sample_num')\n",
        "test_size = 0.3\n",
        "test_sample = all_sample.sample(n=int(all_sample.shape[0]*test_size))\n",
        "print('test sample number:', test_sample.index.to_list())\n",
        "print('test_sample type:', [ml.label_transfer(sample_num) for sample_num in test_sample.index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* optional2: specify 'test_sample' as control variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape: (43301, 82)\n",
            "test shape: (17364, 82)\n",
            "Index(['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0',\n",
            "       '10.0', '11.0', '12.0', '13.0', '14.0', '15.0', '16.0', '17.0', '18.0',\n",
            "       '19.0', '20.0', '21.0', '22.0', '23.0', '24.0', '25.0', '26.0', '27.0',\n",
            "       '28.0', '29.0', '30.0', '31.0', '32.0', '33.0', '34.0', '35.0', '36.0',\n",
            "       '37.0', '38.0', '39.0', '40.0', '41.0', '42.0', '43.0', '44.0', '45.0',\n",
            "       '46.0', '47.0', '48.0', '49.0', '50.0', '51.0', '52.0', '53.0', '54.0',\n",
            "       '55.0', '56.0', '57.0', '58.0', '59.0', '60.0', '61.0', '62.0', '63.0',\n",
            "       '64.0', '65.0', '66.0', '67.0', '68.0', '69.0', '70.0', '71.0', '72.0',\n",
            "       '73.0', '74.0', '75.0', '76.0', '77.0', '78.0', '79.0',\n",
            "       'mean_energy_30_80', 'std_energy_30_80'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "test_set_no = 1\n",
        "X_train, X_test, y_train, y_test = ml.train_test_split(df=X, test_samples=ml.test_sample['set%i'%test_set_no])\n",
        "print(X_train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlklFPAKSgAU"
      },
      "source": [
        "## Auto-sklearn\n",
        "首先我們來測試第一版的 Auto-sklearn。以下是模型常用的超參數以及方法，詳細內容可以參考官方 API [文件](https://automl.github.io/auto-sklearn/master/api.html)。\n",
        "\n",
        "Parameters:\n",
        "- time_left_for_this_task: 搜尋時間(秒)，預設3600秒(6分鐘)。\n",
        "- per_run_time_limit: 每個模型訓練的上限時間，預設為time_left_for_this_task的1/10。\n",
        "- ensemble_size: 模型輸出數量，預設50。\n",
        "- resampling_strategy: 資料採樣方式。為了避免過擬合，可以採用交叉驗證機制。預設方法為最基本的 holdout。\n",
        "\n",
        "Attributes:\n",
        "- cv_results_: 查詢模型搜尋結果以及每個最佳模型的超參數。\n",
        "\n",
        "Methods:\n",
        "- fit: 放入X、y進行模型擬合。\n",
        "- refit: 使用 fit 尋找好的參數後，再使用所有的資料進行最後微調。\n",
        "- predict: 預測並回傳預測類別。\n",
        "- score: 預測成功的比例。\n",
        "- predict_proba: 預測每個類別的機率值。\n",
        "- leaderboard: 顯示 k 個 ensemble 模型並排名。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTqDZHAHYHV5",
        "outputId": "742f4a0f-efbd-4a65-f7d8-6c3bce4390d6"
      },
      "outputs": [],
      "source": [
        "automlclassifierV1 = ml.train_autosklearn_v1_model(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kmzrlWrIguMr",
        "outputId": "2621c6ab-fa16-43f0-e776-a220fc2c159a"
      },
      "outputs": [],
      "source": [
        "# 查看模型參數\n",
        "import pandas as pd\n",
        "df_cv_results = pd.DataFrame(automlclassifierV1.cv_results_).sort_values(by = 'mean_test_score', ascending = False)\n",
        "df_cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "POoJ1OqZhudZ",
        "outputId": "cfb95878-fa39-40ff-bda1-cd7fe47e3ba1"
      },
      "outputs": [],
      "source": [
        "# 模型聚合結果\n",
        "automlclassifierV1.leaderboard(detailed = True, ensemble_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm01Nqagqut2"
      },
      "source": [
        "### 使用 Auto-sklearn 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFBuOfqySgAU",
        "outputId": "c23f9508-ecac-4325-c012-9f45ff4e39f6"
      },
      "outputs": [],
      "source": [
        "automlclassifierV2 = ml.train_autosklearn_v2_model(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance metrics\n",
        "### Performance-over-time plot\n",
        "using the plot to check wether the time limit is sufficient from [example](https://automl.github.io/auto-sklearn/master/examples/40_advanced/example_pandas_train_test.html#sphx-glr-examples-40-advanced-example-pandas-train-test-py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poT = automlclassifierV1.performance_over_time_\n",
        "poT.plot(\n",
        "    x='Timestamp',\n",
        "    kind='line',\n",
        "    legend=True,\n",
        "    title='Auto-sklearn accuracy over time',\n",
        "    grid=True\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix\n",
        ">`ConfusionMatrixDisplay.from_predictions()` is not supported in this version of scikit-learn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = automlclassifierV2.predict(X_test)\n",
        "\n",
        "titles_options = [('Confusion Matrix', None), ('Normalized Confusion Matrix', 'true')]\n",
        "fig, axes = plt.subplots(1, 2, layout='constrained', figsize=(12, 5), sharey='row')\n",
        "\n",
        "for i, (title, normalize) in enumerate(titles_options):\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=[1, 0], normalize=normalize)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['abnormal', 'normal'])\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=axes[i])\n",
        "    axes[i].set_title(title, fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = automlclassifierV1.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUfjcWeoSgAX"
      },
      "source": [
        "## 真實分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYM4YLWASgAY"
      },
      "outputs": [],
      "source": [
        "# 建立測試集的 DataFrame\n",
        "columns = []\n",
        "for i in X_test.columns:\n",
        "    columns.append(str(i))\n",
        "df_test=pd.DataFrame(X_test.to_numpy(), columns=columns, index=X_test.index)\n",
        "df_test['Type'] = y_test\n",
        "pred = automlclassifierV2.predict(X_test)\n",
        "df_test['Predict'] = pred\n",
        "#df_test.to_excel('prediction_window.xlsx') # for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "644MEs8vSgAY",
        "outputId": "7a2ac45b-2533-4d71-bd44-d1e25faaf5de"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='52', y='53', hue='Type', data=df_test, fit_reg=False, legend=False)\n",
        "plt.legend(title='target', loc='upper left', labels=['normal', 'bearing noise', 'unknown noise'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZX94sm6SgAY"
      },
      "source": [
        "## Auto-sklearn (訓練集)預測結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "CN4EFBY5SgAZ",
        "outputId": "063e415b-dee4-4f67-810d-e7e66c6874dc"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='52', y='53', data=df_test, hue=\"Predict\", fit_reg=False, legend=False)\n",
        "plt.legend(title='target', loc='upper left', labels=['normal', 'bearing noise', 'unknown noise'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYVZ0j9gmqV0"
      },
      "source": [
        "## 查看每個模型的權重\n",
        "我們可以使用模型提供的方法查看最終訓練結果，並查看 k 個 Ensemble 模型的訓練結果以及每個模型的權重。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "l6DMaJwtmqmO",
        "outputId": "29d0086b-92ea-4b4b-d823-a663e4a992f0"
      },
      "outputs": [],
      "source": [
        "automlclassifierV2.leaderboard(detailed = True, ensemble_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTZWPJ4jV8VK"
      },
      "source": [
        "## 輸出模型\n",
        "如果想將 AutoML 的模型儲存起來，可以透過 `joblib` 將模型打包匯出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-X1Y3nUywQ",
        "outputId": "ccde6d74-681d-4e44-cdc5-5139b22a38e1"
      },
      "outputs": [],
      "source": [
        "# 匯出模型\n",
        "name = '../../model//%s_set%i_%i'%(keyword, test_set_no, col)\n",
        "ml.save_model(automlclassifierV1, automlclassifierV2, name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjxObE7lVzTD"
      },
      "outputs": [],
      "source": [
        "# 匯入模型\n",
        "from joblib import load\n",
        "clf = load('../../model//100duty_stats//%s_v1.joblib'%name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# detail of the model\n",
        "best_model_info = clf.show_models()\n",
        "print(best_model_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPeQTt4IWHvX",
        "outputId": "fb54883b-e082-4d2a-8975-0572c7a4fb92"
      },
      "outputs": [],
      "source": [
        "# 模型預測測試\n",
        "clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI0Px3DTb7IC"
      },
      "source": [
        "## 視覺化 AutoML 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnobJNANb6QR",
        "outputId": "5a434e32-be79-4daf-ec64-30a3d84932d1"
      },
      "outputs": [],
      "source": [
        "#pip install pipelineprofiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qt-7h4d0Un8k",
        "outputId": "f31a105d-1bd7-43d1-9477-7469b7350d7a"
      },
      "outputs": [],
      "source": [
        "import PipelineProfiler\n",
        "\n",
        "profiler_data= PipelineProfiler.import_autosklearn(automlclassifierV2)\n",
        "PipelineProfiler.plot_pipeline_matrix(profiler_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pxD2PqctjQf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Auto-sklearn(iris-classification).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "autosklearn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
